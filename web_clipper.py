import os
import time
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import requests
from github import Github
import openai
from notion_client import Client
import telegram
import logging
from fastapi import FastAPI, UploadFile, File, HTTPException, Depends, Header, Request, Body
import uvicorn
import asyncio
from concurrent.futures import ThreadPoolExecutor
import shutil
from pathlib import Path
from fastapi.security import APIKeyHeader, HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
import secrets
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from config import CONFIG  # Ê∑ªÂä†ËøôË°åÂú®Êñá‰ª∂ÂºÄÂ§¥
import re
from bs4 import BeautifulSoup  # Ê∑ªÂä†Âà∞ÂØºÂÖ•ÈÉ®ÂàÜ
from fastapi.responses import JSONResponse

# ÈÖçÁΩÆÊó•Âøó
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ËÆæÁΩÆ httpx Êó•ÂøóÁ∫ßÂà´‰∏∫ WARNINGÔºåÈöêËóèËØ∑Ê±ÇÊó•Âøó
logging.getLogger("httpx").setLevel(logging.WARNING)

# ÈÖçÁΩÆÈôêÂà∂
MAX_FILE_SIZE = CONFIG.get('max_file_size', 10 * 1024 * 1024)  # ‰ªéÈÖçÁΩÆ‰∏≠Ëé∑ÂèñÊúÄÂ§ßÊñá‰ª∂Â§ßÂ∞è
#ALLOWED_EXTENSIONS = {'.html', '.htm'}
ALLOWED_EXTENSIONS = set(CONFIG.get('allowed_extensions', ['.html', '.htm']))
API_KEY_NAME = "X-API-Key"
api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=True)

# ÂàõÂª∫Â∫îÁî®ÂíåÈôêÈÄüÂô®
app = FastAPI()
limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

handler = None
UPLOAD_DIR = Path("uploads")

# ÊõøÊç¢ÂéüÊù•ÁöÑ API_KEY_NAME Âíå api_key_header
security = HTTPBearer()

async def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """È™åËØÅ Bearer ‰ª§Áâå"""
    token = credentials.credentials
    if token != CONFIG.get('api_key'):
        raise HTTPException(
            status_code=401,
            detail="Invalid authentication token",
            headers={"WWW-Authenticate": "Bearer"},
        )
    return token

def verify_file(file: UploadFile):
    """È™åËØÅÊñá‰ª∂"""
    # Ê£ÄÊü•Êñá‰ª∂Êâ©Â±ïÂêç
    file_ext = Path(file.filename).suffix.lower()
    if file_ext not in ALLOWED_EXTENSIONS:
        raise HTTPException(
            status_code=400,
            detail=f"File type not allowed. Allowed types: {', '.join(ALLOWED_EXTENSIONS)}"
        )
    
    # Ê£ÄÊü•Êñá‰ª∂Â§ßÂ∞è
    file.file.seek(0, 2)  # ÁßªÂà∞Êñá‰ª∂Êú´Â∞æ
    size = file.file.tell()  # Ëé∑ÂèñÊñá‰ª∂Â§ßÂ∞è
    file.file.seek(0)  # ÈáçÁΩÆÊñá‰ª∂ÊåáÈíà
    
    if size > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=400,
            detail=f"File too large. Maximum size allowed: {MAX_FILE_SIZE/1024/1024}MB"
        )

def parse_filename(filename):
    """‰ªéÊñá‰ª∂ÂêçËß£ÊûêURL
    filename format: {random_prefix}_url.html (ÂÖ∂‰∏≠url‰∏≠ÁöÑ/Ë¢´ÊõøÊç¢‰∏∫$)
    """
    try:
        # ÁßªÈô§ .html ÂêéÁºÄ
        name_without_ext = filename.rsplit('.', 1)[0]
        
        # ÁßªÈô§ÈöèÊú∫ÂâçÁºÄÔºàÂ¶ÇÊûúÂ≠òÂú®Ôºâ
        if '_' in name_without_ext:
            name_without_ext = name_without_ext.split('_', 1)[1]
        
        # ÊÅ¢Â§çURL‰∏≠ÁöÑÊñúÊù†
        original_url = name_without_ext.replace('$', '/')
        
        logger.info(f"‰ªéÊñá‰ª∂ÂêçËß£ÊûêÂá∫ÂéüÂßãURL: {original_url}")
        return {
            'original_url': original_url
        }
    except Exception as e:
        logger.error(f"Ëß£ÊûêÊñá‰ª∂ÂêçÂ§±Ë¥•: {str(e)}")
        return {
            'original_url': ''
        }

class WebClipperHandler:
    def __init__(self, config):
        self.config = config
        self.github_client = Github(config['github_token'])
        self.notion_client = Client(auth=config['notion_token'])
        self.telegram_bot = telegram.Bot(token=config['telegram_token'])
        
        # ÈÖçÁΩÆ OpenAI
        openai.api_key = config['openai_api_key']
        if 'openai_base_url' in config:
            openai.base_url = config['openai_base_url']
            logger.info(f"‰ΩøÁî®Ëá™ÂÆö‰πâ OpenAI API URL: {config['openai_base_url']}")

    async def process_file(self, file_path: Path, original_url: str = ''):
        """Â§ÑÁêÜ‰∏ä‰º†ÁöÑÊñá‰ª∂"""
        try:
            logger.info("üîÑ ÂºÄÂßãÂ§ÑÁêÜÊñ∞ÁöÑÁΩëÈ°µÂâ™Ëóè...")
            
            # 1. ‰∏ä‰º†Âà∞ GitHub Pages
            filename, github_url = self.upload_to_github(str(file_path))
            logger.info(f"üì§ GitHub ‰∏ä‰º†ÊàêÂäü: {github_url}")
            
            # Ëé∑ÂèñÈ°µÈù¢ÂÜÖÂÆπÂíåÊ†áÈ¢ò
            title, content = await self.get_page_content(github_url)
            logger.info(f"üìë È°µÈù¢Ê†áÈ¢ò: {title}")
            
            # Â¶ÇÊûúÊ≤°ÊúâÊèê‰æõÂéüÂßã URLÔºåÂàô‰ªéÊñá‰ª∂ÂêçËß£Êûê
            if not original_url:
                file_info = parse_filename(filename)
                original_url = file_info['original_url']
            
            # 2. ÁîüÊàêÊëòË¶ÅÂíåÊ†áÁ≠æ
            md_content = self.url2md(github_url, content)
            summary, tags = self.generate_summary_tags(md_content)
            logger.info(f"üìù ÊëòË¶Å: {summary[:100]}...")
            logger.info(f"üè∑Ô∏è Ê†áÁ≠æ: {', '.join(tags)}")
            
            # 3. ‰øùÂ≠òÂà∞ Notion
            notion_url = self.save_to_notion({
                'title': title,
                'original_url': original_url,
                'snapshot_url': github_url,
                'summary': summary,
                'tags': tags,
                'created_at': time.time()
            })
            logger.info(f"üìì Notion ‰øùÂ≠òÊàêÂäü")
            
            # 4. ÂèëÈÄÅ Telegram ÈÄöÁü•
            notification = (
                f"‚ú® Êñ∞ÁöÑÁΩëÈ°µÂâ™Ëóè\n\n"
                f"üìë {title}\n\n"
                f"üìù {summary}\n\n"
                f"üîó ÂéüÂßãÈìæÊé•Ôºö{original_url}\n"
                f"üìö Âø´ÁÖßÈìæÊé•Ôºö{github_url}"
            )
            await self.send_telegram_notification(notification)
            
            logger.info("=" * 50)
            logger.info("‚ú® ÁΩëÈ°µÂâ™ËóèÂ§ÑÁêÜÂÆåÊàê!")
            logger.info(f"üìç ÂéüÂßãÈìæÊé•: {original_url}")
            logger.info(f"üîó GitHubÈ¢ÑËßà: {github_url}")
            logger.info(f"üìö NotionÁ¨îËÆ∞: {notion_url}")
            logger.info("=" * 50)
            
            return {
                "status": "success",
                "github_url": github_url,
                "notion_url": notion_url
            }
            
        except Exception as e:
            error_msg = f"‚ùå Â§ÑÁêÜÂ§±Ë¥•: {str(e)}"
            logger.error(error_msg)
            logger.error("=" * 50)
            await self.send_telegram_notification(error_msg)
            raise

    def upload_to_github(self, html_path):
        """‰∏ä‰º† HTML Êñá‰ª∂Âà∞ GitHub Pages"""
        filename = os.path.basename(html_path)
        
        with open(html_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        repo = self.github_client.get_repo(self.config['github_repo'])
        file_path = f"clips/{filename}"
        repo.create_file(
            file_path,
            f"Add web clip: {filename}",
            content,
            branch="main"
        )
        
        github_url = f"https://{self.config['github_pages_domain']}/{self.config['github_repo'].split('/')[1]}/clips/{filename}"
        
        # Á≠âÂæÖ GitHub Pages ÈÉ®ÁΩ≤
        max_retries = self.config.get('github_pages_max_retries', 60)
        for attempt in range(max_retries):
            try:
                response = requests.get(github_url)
                if response.status_code == 200:
                    break
                time.sleep(5)
            except Exception:
                time.sleep(5)
        
        return filename, github_url
    
    def url2md(self, url, bs4_content, max_retries=60):
        """Â∞Ü URL ËΩ¨Êç¢‰∏∫ Markdown"""
        for attempt in range(max_retries):
            try:
                md_url = f"https://r.jina.ai/{url}"
                response = requests.get(md_url)
                if response.status_code == 200:
                    md_content = response.text
                    return md_content
            except Exception:
                time.sleep(10)
        return bs4_content

    def generate_summary_tags(self, content):
        """‰ΩøÁî® AI ÁîüÊàêÊëòË¶ÅÂíåÊ†áÁ≠æ"""
        try:
            client = openai.OpenAI(
                api_key=self.config['openai_api_key'],
                base_url=self.config.get('openai_base_url')
            )
            
            model = self.config.get('openai_model', 'gpt-3.5-turbo')
            
            response = client.chat.completions.create(
                model=model,
                messages=[{
                    "role": "user",
                    "content": """ËØ∑‰∏∫‰ª•‰∏ãÁΩëÈ°µ(Â∑≤ËΩ¨Êç¢‰∏∫MarkdownÊ†ºÂºè)ÂÜÖÂÆπÁîüÊàêÁÆÄÁü≠ÊëòË¶ÅÂíåÁõ∏ÂÖ≥Ê†áÁ≠æ„ÄÇ 
                    ËØ∑‰∏•Ê†ºÊåâÁÖß‰ª•‰∏ãÊ†ºÂºèËøîÂõû(Ëã±ÊñáÁΩëÈ°µËØ∑‰ª•‰∏≠ÊñáËøîÂõû)Ôºö
                    ÊëòË¶ÅÔºö[100Â≠ó‰ª•ÂÜÖÁöÑÊëòË¶Å]
                    Ê†áÁ≠æÔºötag1Ôºåtag2Ôºåtag3Ôºåtag4Ôºåtag5

                    ÁΩëÈ°µ(Â∑≤ËΩ¨Êç¢‰∏∫markdownÊ†ºÂºè)ÂÜÖÂÆπÔºö
                    """ + content[:5000] + "..."
                }]
            )

            
            result = response.choices[0].message.content
            
            try:
                parts = result.split('\n')
                summary_part = next(p for p in parts if p.startswith('ÊëòË¶ÅÔºö'))
                tags_part = next(p for p in parts if p.startswith('Ê†áÁ≠æÔºö'))
                
                summary = summary_part.replace('ÊëòË¶ÅÔºö', '').strip()
                tags_str = tags_part.replace('Ê†áÁ≠æÔºö', '').strip()
                tags = [
                    tag.strip()[:20]
                    for tag in tags_str.replace('Ôºå', ',').split(',')
                    if tag.strip()
                ]
                
                return summary, tags
                
            except Exception as e:
                logger.error(f"Ëß£Êûê AI ÂìçÂ∫îÂ§±Ë¥•: {str(e)}")
                return "Êó†Ê≥ïËß£ÊûêÊëòË¶Å", ["Êú™ÂàÜÁ±ª"]
            
        except Exception as e:
            logger.error(f"OpenAI API Ë∞ÉÁî®Â§±Ë¥•: {str(e)}")
            return "Êó†Ê≥ïÁîüÊàêÊëòË¶Å", ["Êú™ÂàÜÁ±ª"]

    def save_to_notion(self, data):
        """‰øùÂ≠òÂà∞ Notion Êï∞ÊçÆÂ∫ì"""
        try:
            tags = data.get('tags', [])
            if not tags:
                tags = ["Êú™ÂàÜÁ±ª"]
            
            current_time = time.strftime('%Y-%m-%dT%H:%M:%S.000Z', 
                                       time.gmtime(data['created_at']))
            
            properties = {
                "Title": {"title": [{"text": {"content": data['title']}}]},
                "OriginalURL": {"url": data['original_url'] if data['original_url'] else None},
                "SnapshotURL": {"url": data['snapshot_url']},
                "Summary": {"rich_text": [{"text": {"content": data['summary']}}]},
                "Tags": {"multi_select": [{"name": tag} for tag in tags if tag.strip()]},
                "Created": {"date": {"start": current_time}}
            }
            
            response = self.notion_client.pages.create(
                parent={"database_id": self.config['notion_database_id']},
                properties=properties
            )
            
            return response['url']
            
        except Exception as e:
            logger.error(f"‰øùÂ≠òÂà∞ Notion Â§±Ë¥•: {str(e)}")
            if hasattr(e, 'response'):
                logger.error(f"Notion API ÂìçÂ∫î: {e.response.text}")
            raise

    async def send_telegram_notification(self, message):
        """ÂèëÈÄÅ Telegram ÈÄöÁü•"""
        await self.telegram_bot.send_message(
            chat_id=self.config['telegram_chat_id'],
            text=message
        )

    async def get_page_content(self, url, max_retries=60):
        """‰ªéÈÉ®ÁΩ≤ÁöÑÈ°µÈù¢Ëé∑ÂèñÊ†áÈ¢òÂíåÂÜÖÂÆπ"""
        for attempt in range(max_retries):
            try:
                response = requests.get(url)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    # Ëé∑ÂèñÊ†áÈ¢ò
                    title = None
                    if soup.title:
                        title = soup.title.string
                    if not title and soup.h1:
                        title = soup.h1.get_text(strip=True)
                    if not title:
                        for tag in ['h2', 'h3', 'h4', 'h5', 'h6']:
                            if soup.find(tag):
                                title = soup.find(tag).get_text(strip=True)
                                break
                    
                    # Ê∏ÖÁêÜÊ†áÈ¢ò
                    if title:
                        title = ' '.join(title.split())
                        title = re.sub(r'\s*[-|]\s*.*$', '', title)
                    else:
                        title = os.path.basename(url)
                    
                    # ÊèêÂèñÊ≠£ÊñáÂÜÖÂÆπ
                    for script in soup(["script", "style"]):
                        script.decompose()
                    
                    text = soup.get_text()
                    lines = (line.strip() for line in text.splitlines())
                    chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
                    text = ' '.join(chunk for chunk in chunks if chunk)
                    
                    return title, text
                    
                await asyncio.sleep(5)
                
            except Exception:
                await asyncio.sleep(5)
        
        return os.path.basename(url), ""

@app.on_event("startup")
async def startup_event():
    """ÂêØÂä®Êó∂ÂàùÂßãÂåñ"""
    global handler
    from config import CONFIG
    handler = WebClipperHandler(CONFIG)
    UPLOAD_DIR.mkdir(exist_ok=True)
    
    # Â¶ÇÊûúÈÖçÁΩÆ‰∏≠Ê≤°Êúâ API keyÔºåÁîüÊàê‰∏Ä‰∏™
    if 'api_key' not in CONFIG:
        CONFIG['api_key'] = secrets.token_urlsafe(32)
        logger.info(f"Generated new API key: {CONFIG['api_key']}")

@app.post("/upload/")
@limiter.limit("10/minute", key_func=get_remote_address)
async def upload_file(
    request: Request,
    token: str = Depends(verify_token)
):
    """Êñá‰ª∂‰∏ä‰º†Êé•Âè£"""
    try:
        form = await request.form()
        original_url = form.get('url', '')
        
        # Ëé∑ÂèñÊñá‰ª∂ÂÜÖÂÆπ
        file = None
        for field_name, field_value in form.items():
            if hasattr(field_value, 'filename') and hasattr(field_value, 'read'):
                file = field_value
                break
        
        if not file:
            raise HTTPException(
                status_code=400,
                detail="No file content found in form data"
            )
        
        filename = file.filename
        content = await file.read()
        
        # È™åËØÅÂíå‰øùÂ≠òÊñá‰ª∂
        file_ext = Path(filename).suffix.lower()
        if not file_ext:
            filename += '.html'
        elif file_ext not in ALLOWED_EXTENSIONS:
            raise HTTPException(
                status_code=400,
                detail=f"File type not allowed. Allowed types: {', '.join(ALLOWED_EXTENSIONS)}"
            )
        
        if len(content) > MAX_FILE_SIZE:
            raise HTTPException(
                status_code=400,
                detail=f"File too large. Maximum size allowed: {MAX_FILE_SIZE/1024/1024}MB"
            )
        
        # ‰øùÂ≠òÊñá‰ª∂
        safe_filename = f"{secrets.token_hex(8)}_{filename}"
        file_path = UPLOAD_DIR / safe_filename
        
        with open(file_path, "wb") as f:
            f.write(content)
        
        try:
            result = await handler.process_file(file_path, original_url)
            return result
        finally:
            if file_path.exists():
                file_path.unlink()
                
    except HTTPException:
        raise
    except Exception as e:
        error_msg = f"‰∏ä‰º†Â§±Ë¥•: {str(e)}"
        logger.error(error_msg)
        raise HTTPException(
            status_code=500,
            detail=str(e)
        )

def start_server(host="0.0.0.0", port=8000):
    """ÂêØÂä®ÊúçÂä°Âô®"""
    uvicorn.run(app, host=host, port=port) 
